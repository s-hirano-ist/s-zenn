---
title: "10åˆ†ã§å‹•ã‹ã™Weaviateï¼ˆMacÃ—Dockerï¼‰"
emoji: "ğŸ·"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics:
  - "docker"
  - "mac"
  - "llm"
  - "ollama"
  - "rag"
published: false
---

## ã¯ã˜ã‚ã«

ãŸã ã®ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒWeaviateã‚’Macã§å‹•ã‹ã—ãŸå‚™å¿˜éŒ²ã§ã™ã€‚
RAGã‚’ã¤ãã£ã¦ã„ãã¾ã™ã€‚

## å®Ÿè¡Œç’°å¢ƒ

- Mac mini M4ãƒãƒƒãƒ— 32GBãƒ¡ãƒ¢ãƒª
- macOS Sequoia 15.3.1

## äº‹å‰æº–å‚™

1. [Ollama](https://ollama.com/)ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

## ç’°å¢ƒæ§‹ç¯‰

[Weaviateã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://weaviate.io/developers/weaviate/quickstart/local)ã«å¾“ã£ã¦ã€ç’°å¢ƒæ§‹ç¯‰ã‚’è¡Œã„ã¾ã™ã€‚

1. Ollamaãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

    ```bash
    ollama pull nomic-embed-text
    ollama pull llama3.2
    ```

1. `compose.yaml`ã®ä½œæˆ

    ```yaml
    services:
    weaviate:
        command:
        - --host
        - 0.0.0.0
        - --port
        - '8080'
        - --scheme
        - http
        image: cr.weaviate.io/semitechnologies/weaviate:1.29.0
        ports:
        - 8080:8080
        - 50051:50051
        volumes:
        - weaviate_data:/var/lib/weaviate
        restart: on-failure:0
        environment:
        QUERY_DEFAULTS_LIMIT: 25
        AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
        PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
        ENABLE_API_BASED_MODULES: 'true'
        ENABLE_MODULES: 'text2vec-ollama,generative-ollama'
        CLUSTER_HOSTNAME: 'node1'
    volumes:
    weaviate_data:
    ```

1. ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•

    ```bash
    docker compose up -d
    ```

## æ¤œè¨¼çµæœ

1. Weaviateã®èµ·å‹•ã®ç¢ºèª

    ```typescript
    import weaviate, { type WeaviateClient } from "weaviate-client";
    const client: WeaviateClient = await weaviate.connectToLocal();
    const clientReadiness = await client.isReady();
    console.log(clientReadiness); // Should return `true`
    client.close(); // Close the client connection
    ```

1. Collectionã®ä½œæˆ

    ```typescript
    import weaviate, {
        type WeaviateClient,
        vectorizer,
        generative,
    } from "weaviate-client";

    const client: WeaviateClient = await weaviate.connectToLocal();

    await client.collections.create({
        name: "Question",
        vectorizers: vectorizer.text2VecOllama({
            // Configure the Ollama embedding integration
            apiEndpoint: "http://host.docker.internal:11434", // Allow Weaviate from within a Docker container to contact your Ollama instance
            model: "nomic-embed-text", // The model to use
        }),
        generative: generative.ollama({
            // Configure the Ollama generative integration
            apiEndpoint: "http://host.docker.internal:11434", // Allow Weaviate from within a Docker container to contact your Ollama instance
            model: "llama3.2", // The model to use
        }),
    });
    client.close(); // Close the client connection
    ```

1. ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥

    ```typescript
    import weaviate, { type WeaviateClient } from "weaviate-client";
    const client: WeaviateClient = await weaviate.connectToLocal();
    // Load data
    async function getJsonData() {
        const file = await fetch(
            "https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json",
        );
        return file.json();
    }
    // Note: The TS client does not have a `batch` method yet
    // We use `insertMany` instead, which sends all of the data in one request
    async function importQuestions() {
        const questions = client.collections.get("Question");
        const data = await getJsonData();
        const result = await questions.data.insertMany(data);
        console.log("Insertion response: ", result);
    }
    await importQuestions();
    client.close(); // Close the client connection
    ```

1. ã‚¯ã‚¨ãƒªæ¤œç´¢

    ```typescript
    import weaviate, { type WeaviateClient } from "weaviate-client";
    const client: WeaviateClient = await weaviate.connectToLocal();
    const questions = client.collections.get("Question");
    const result = await questions.query.nearText("biology", {
        limit: 2,
    });
    for (const item of result.objects) {
        console.log(JSON.stringify(item.properties, null, 2));
    }
    client.close(); // Close the client connection
    ```

1. RAGã®å®Ÿè¡Œ

    ```typescript
    import weaviate, { type WeaviateClient } from "weaviate-client";
    const client: WeaviateClient = await weaviate.connectToLocal();
    const questions = client.collections.get("Question");
    const result = await questions.generate.nearText(
        "biology",
        { groupedTask: "Write a tweet with emojis about these facts." },
        { limit: 2 },
    );
    console.log(result.generated);
    client.close(); // Close the client connection
    ```

## æ„Ÿæƒ³

Weaviateå°‚ç”¨ã®SDKãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ã¯ã€ä¸‡ãŒä¸€ä¹—ã‚Šæ›ãˆãŒå¿…è¦ã«ãªã£ãŸå ´åˆã«å¤§å¤‰ã«ãªã‚‹ãªã¨æ„Ÿã˜ãŸã€‚
`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ = AWS S3`ã®ã‚ˆã†ã«ã€`ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ = Weaviate`ã¨ã„ã†ã‚ˆã†ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã§æ¨™æº–åŒ–ã—ã¦ã»ã—ã„ã€‚
