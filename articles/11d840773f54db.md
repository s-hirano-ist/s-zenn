---
title: "10分で動かすローカルLLM（Mac×Ollama×DeepSeek編）"
emoji: "🐷"
type: "tech" # tech: 技術記事 / idea: アイデア
topics:
  - "mac"
  - "llm"
  - "ollama"
  - "deepseek"
published: true
published_at: "2025-02-22 12:33"
---

## はじめに

ただのフロントエンドエンジニアがDeepSeekをMacで動かした備忘録です。
[以前の投稿](https://zenn.dev/s_hirano_ist/articles/7dcfeac4086b51)ではDockerを用いて動かしたのですが、GPUを利用できず、推論が遅かったため、本投稿ではネイティブアプリとして動かします。

なお、各手順は公式READMEを参考にしております。

## 実行環境

- Mac mini M4チップ 32GBメモリ
- macOS Sequoia 15.3.1

## 環境構築

1. 事前準備

   1. [Homebrew](https://brew.sh/ja/)のインストール

1. [Ollama](https://github.com/ollama/ollama)の環境構築

   ```bash
   brew install ollama
   brew services start ollama
   ```

1. [Ollama](https://github.com/ollama/ollama)の実行

   ```bash
   ollama run deepseek-r1:32b
   ```

   ※ 実行できるモデルは[こちら](https://ollama.com/search)を確認してください。

## 実行結果

[以前の投稿](https://zenn.dev/s_hirano_ist/articles/7dcfeac4086b51)で、32Bまでは動くことを確認済みなため、いきなり32Bモデルを実行しました。

### deepseek-r1 32Bモデル

```bash
% ollama run deepseek-r1:32b

>>> Difyとは?
<think>

</think>

Dify（ディフィ）は、AIを活用した会話型の情報検索サービスです。ユーザーが質問や疑問を投げかけると、DifyがAIで分析し、最適な回答や関連情報を提供します。検索エンジンやデータベースを活用しながら、自然言語処理（NLP）技術により、理
解しやすい形で情報を返すのが特徴です。

### 主な機能
1. **会話型インタフェース**：ユーザーとのやりとりを通じて、深く情報を引き出す。
2. **AI分析**：質問を解析し、関連するデータや情報を探し出す。
3. **多様な応答形式**：文章、リスト、テーブル等形式で回答します。

### 利用シーン
- **教育**：学生が勉強やレポート作成で活用。
- **ビジネス**：仕事での疑問解決や情報収集に使用。
- **一般ユーザー**：日常の知的好奇心や問題解決に役立てます。

Difyは、AIと人間の協力によって、効率的に情報を得られるツールです。

>>> Send a message (/? for help)
```

Dockerの時と比べ、10倍位早くなりました。
Apple siliconのMacだとGPU使うの一苦労ですね（何もしてない）。

## 感想

次回は[Dify](https://github.com/langgenius/dify)を動かしてみます。
